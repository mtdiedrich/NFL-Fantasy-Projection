{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on Saving Data\n",
    "Web scrapers face a unique set of challenges, the most interesting of which may be the adversarial nature of it all. In general, webmasters do not want their data scraped, and they have a handful of tools available to them to inconvenience the webscraper. The site from which we'll be scraping data, profootballreference, deters webscrapers by temporarily blocking traffic from users that make too many requests in too short of a time period. To counteract this, we'll make use of python's `time.sleep()` function, but, where possible, we'll also be saving webpages locally. This will allow us ad hoc access without the need to wait through numerous calls to `time.sleep()`.\n",
    "\n",
    "# Data Collection\n",
    "\n",
    "Naturally, we must begin with collecting the data. This will involve scraping profootballreference.\n",
    "\n",
    "Let's define our imports and some helper functions to keep our code organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import html5lib\n",
    "\n",
    "\n",
    "def get_passing_url(year):\n",
    "    return f\"https://www.pro-football-reference.com/years/{year}/passing.htm\"\n",
    "\n",
    "\n",
    "def get_rushing_url(year):\n",
    "    return f\"https://www.pro-football-reference.com/years/{year}/rushing.htm\"\n",
    "\n",
    "\n",
    "def get_receiving_url(year):\n",
    "    return f\"https://www.pro-football-reference.com/years/{year}/receiving.htm\"\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_valid_subdirectories(soup):\n",
    "    html_subdirectories = soup.find_all(\"a\")\n",
    "    valid_subdirectories = [link for link in html_subdirectories if '/players/' in str(link)]\n",
    "    subdirectories = [link.get('href') for link in valid_subdirectories]\n",
    "    return subdirectories\n",
    "\n",
    "\n",
    "def make_directory(name):\n",
    "    import os\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now our first step will involve iterating through each season of interest and getting the webpages for that season's passing, rushing, and receiving stats. \n",
    "\n",
    "From each of those webpages, we will extract every link that leads to a player's individual stats page. We will store all of these links in a list called `player_links`, which we will then make unique.\n",
    "\n",
    "#### A Note on Seasons\n",
    "\n",
    "How many seasons should would be interested in? That's a difficult question to answer. The naive perspective suggest that we want *all* of the available data, and, while there would be some merit to that approach, anyone familiar wih the NFL knows that the game has evolved over time; the way that the game was played in its earliest form has little in common with the game as it exists today, and historical data would feature trends that are not mirrored today. For that reason, we want to focus on \"modern\" data.\n",
    "\n",
    "Still, defining 'modern\" is not easy. When discussing the NFL, \"modern\" generally refers to any season after the NFL-AFL merger in 1970. In most contexts, this is a good defintion, but, for the purpose of this project, I don't feel that it is sufficient. The way that the game is played and the ways in which players are utilized continued to evolve after the merger, and the data reflects that. For that reason, I had to settle on a different defintion of \"modern.\"\n",
    "\n",
    "For the purposes of this project, the modern NFL began in 2012. In 2011, the union representing the players (the NFL Player's Association) negotiated a new collective bargaining agreement (CBA) with the team owners. The CBA had *massive* rammifications, many of which have surely gone unnoticed, but one of the more visible effects has been the reduced interest in signing veteran players to be minor contributors. To oversimplify a nuanced and fascinating topic: the CBA that took prior to the 2012 season limited earnings for rookie players, increasing their value relative to their veteran counterparts. The demand for low-level veterans plummted because rookie contract players offer 90% of the performance for 50% of the price (numbers that I've fabricated to demonstrate the point). This shift meant that many positions (especially runningback) skewed much younger after the CBA took effect. For this project, we want data that reflects current positional values, thus, we are using only data from after the 2011 CBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_links = []\n",
    "for year in tqdm.tqdm(range(2012, 2023)):\n",
    "    # Passing\n",
    "    make_directory(f\"../data/passing\")\n",
    "    passing_url = get_passing_url(year)\n",
    "    passing_soup = get_soup(passing_url)\n",
    "    \n",
    "    with open(f\"../data/passing/{year}.html\", \"w\") as file:\n",
    "        file.write(str(passing_soup))\n",
    "    \n",
    "    passing_table = passing_soup.find(id=\"passing\")\n",
    "    passing_subdirectories = get_valid_subdirectories(passing_table)\n",
    "    player_links.extend(passing_subdirectories)\n",
    "    # Rushing\n",
    "    make_directory(f\"../data/rushing\")\n",
    "    rushing_url = get_rushing_url(year)\n",
    "    rushing_soup = get_soup(rushing_url)\n",
    "    \n",
    "    with open(f\"../data/rushing/{year}.html\", \"w\") as file:\n",
    "        file.write(str(rushing_soup))\n",
    "    \n",
    "    rushing_table = rushing_soup.find(id=\"rushing\")\n",
    "    rushing_subdirectories = get_valid_subdirectories(rushing_table)\n",
    "    player_links.extend(rushing_subdirectories)\n",
    "    # Receiving\n",
    "    receiving_url = get_receiving_url(year)\n",
    "    receiving_soup = get_soup(receiving_url)\n",
    "    \n",
    "    with open(f\"../data/receiving/{year}.html\", \"w\") as file:\n",
    "        file.write(str(receiving_soup))\n",
    "    \n",
    "    receiving_table = receiving_soup.find(id=\"receiving\")\n",
    "    receiving_subdirectories = get_valid_subdirectories(receiving_table)\n",
    "    player_links.extend(receiving_subdirectories)\n",
    "    # Wait 30 seconds to avoid getting blocked\n",
    "    time.sleep(30)\n",
    "    \n",
    "# Make unique\n",
    "player_links = list(set(player_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have a list of subdirectories for every player that passed, rushed, or caught a ball in since 2011. We can append these subdirectories to a base URL to get links to each player's page.\n",
    "\n",
    "Next we'll have to parse the HTML of each player's page and extract the data. Because doing so would involve several layers of data structure nesting, I opted instead to create a `Player` class to hold each player's data. Because \"Tell, Don't Ask\" programming is a good practice, and because we are good little object-oriented programmers, we'll instantiate the class with just a single subdirectory and have it handle the HTML parsing. Unfortunately, the format of each player's webpage varies depending on the player's position, meaning we need position-specific parsing functionality, and, thus, we will have `Player` be an abstract class, and we'll create position classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class Player(ABC):\n",
    "    def __init__(self, link):\n",
    "        self.url = f\"https://www.pro-football-reference.com{link}\"\n",
    "        self.soup = self.get_soup()\n",
    "\n",
    "    def get_soup(self):\n",
    "        page = requests.get(self.url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    @abstractmethod\n",
    "    def some_player_method(self):\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, link):\n",
    "        position = cls._get_position_static(link)\n",
    "        if position == 'QB':\n",
    "            return Quarterback(link)\n",
    "        else:\n",
    "            return SkillPosition(link)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_position_static(link):\n",
    "        url = f\"https://www.pro-football-reference.com{link}\"\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        position_strong_tag = soup.find('strong', string='Position')\n",
    "        if position_strong_tag and position_strong_tag.next_sibling:\n",
    "            position = position_strong_tag.next_sibling.strip(': ').strip()\n",
    "            return position\n",
    "        return None\n",
    "\n",
    "\n",
    "class Quarterback(Player):\n",
    "    def __init__(self, link):\n",
    "        super().__init__(link)\n",
    "        self._set_throws()\n",
    "        \n",
    "    def some_player_method(self):\n",
    "        print('Quarterback method')\n",
    "\n",
    "    def _set_throws(self):\n",
    "        self.throws = self.get_throws()\n",
    "\n",
    "    def get_throws(self):\n",
    "        throws_strong_tag = self.soup.find('strong', string='Throws:')\n",
    "        if throws_strong_tag and throws_strong_tag.next_sibling:\n",
    "            throws = throws_strong_tag.next_sibling.strip(': ').strip()\n",
    "            return throws\n",
    "        return None\n",
    "    \n",
    "class SkillPosition(Player):\n",
    "    def some_player_method(self):\n",
    "        # Implementation specific to SkillPosition\n",
    "        print('SkillPosition method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thwarted by pfr's rate limiting again..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
